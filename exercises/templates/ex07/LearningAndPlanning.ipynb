{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "006fc2a74f64e730de52ea25472ac4be",
     "grade": false,
     "grade_id": "cell-a3619358b7078463",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 7) Learning and Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b9144af5a1d85f9ce0f961ebeeb0d9a",
     "grade": false,
     "grade_id": "cell-3353a9b5529d1970",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, we will again investigate the inverted pendulum from the `gymnasium` environment. We want to check, which benefits the implementation of planning offers.\n",
    "\n",
    "Please note that the parameter $n$ has a different meaning in the context of planning (number of planning steps per actual step) than in the context of n-step learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3622e7222b92491548fc0586a9f7a33",
     "grade": false,
     "grade_id": "cell-341da976c725d0ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "gym.logger.set_level(40)\n",
    "plt.style.use('seaborn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1982763b565d077672675aba272ffbd",
     "grade": false,
     "grade_id": "cell-92cdcff0f0a476ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will reuse the discretization routine from the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d8cdd5116a67e41939084512f4fe9c9",
     "grade": false,
     "grade_id": "cell-be904d3f45f5ff7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d_T = 15\n",
    "d_theta = 15\n",
    "d_omega = 15\n",
    "\n",
    "\n",
    "def discretize_state(states):\n",
    "    limits = [1, 1, 8]\n",
    "    nb_disc_intervals = [d_theta, d_theta, d_omega]\n",
    "\n",
    "    # bring to value range [-1, 1]\n",
    "    norm_states = [state / limit for state, limit in zip(states, limits)]\n",
    "    interval_lengths = [2 / d for d in nb_disc_intervals]\n",
    "    disc_state = [(norm_state + 1) // interval_length for norm_state,\n",
    "                  interval_length in zip(norm_states, interval_lengths)]\n",
    "    disc_state = [(state - 1) if state == d else state for state,\n",
    "                  d in zip(disc_state, nb_disc_intervals)]  # ensure that disc_state < d\n",
    "\n",
    "    return np.array(disc_state)\n",
    "\n",
    "\n",
    "def continualize_action(disc_action):\n",
    "    limit = 2\n",
    "    interval_length = 2 / (d_T-1)\n",
    "    norm_action = disc_action * interval_length\n",
    "    cont_action = (norm_action - 1) * limit\n",
    "    return np.array(cont_action).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dc26bde77ec0598d6b4688f01a1442b",
     "grade": false,
     "grade_id": "cell-4846b5fbbddf7cc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1) Dyna-Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c581250c5c97b741bb0bbcb9e9b46699",
     "grade": false,
     "grade_id": "cell-785833d7145b35e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write a Dyna-Q algorithm to solve the inverted pendulum. Check the quality of the result for different number of episodes, number of steps per episode and number of planning steps per interaction.\n",
    "\n",
    "Make sure that the total number of learning steps stays the same for different n, such that comparisons are fair:\n",
    "\n",
    "$\\text{episodes} \\cdot \\text{steps} \\cdot (1+n) = \\text{const.}$\n",
    "\n",
    "Interesting metrics for a comparison could be e.g. the execution time (the tqdm loading bar shows execution time of loops, alternatively you can use the time.time() command to get the momentary system time in seconds) and training stability. \n",
    "\n",
    "![](DynaQ_Algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43a1b718627ad16d3520e7c35abb5446",
     "grade": false,
     "grade_id": "cell-46e520741979f3d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Solution 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65897f0cae554e8a32ad59ea33289040",
     "grade": true,
     "grade_id": "cell-bcde5eb71e92fdc2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6b11c3a2ddbf455ba192156f9d7ae32",
     "grade": false,
     "grade_id": "cell-8c85133baab1af6a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pendulumDynaQ(alpha, gamma, epsilon, n, nb_episodes, nb_steps):\n",
    "\n",
    "    env = gym.make('Pendulum-v1')\n",
    "    env = env.unwrapped\n",
    "\n",
    "    action_values = np.zeros([d_theta, d_theta, d_omega, d_T])\n",
    "    pi = np.zeros([d_theta, d_theta, d_omega])\n",
    "\n",
    "    model = {} # dictionary\n",
    "\n",
    "    cumulative_reward_history = [] # we can use this to figure out how well the learning worked\n",
    "    pbar = tqdm(range(nb_episodes))\n",
    "\n",
    "    for j in pbar:\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return cumulative_reward_history, pi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb52ea33847f911b0c3d3684bb661ee5",
     "grade": false,
     "grade_id": "cell-ad72a11ce720c2ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Function to evaluate and render the measurement using the gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "527574d1699c79dc56dc78673cbe236b",
     "grade": false,
     "grade_id": "cell-1e3b5eabe632e0b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def experiment(pi, nb_steps=300, render=False):\n",
    "# Runs the inverted pendulum experiment using policy pi for nb_steps steps\n",
    "\n",
    "    if render:\n",
    "        env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "    else:\n",
    "        env = gym.make('Pendulum-v1')\n",
    "    env = env.unwrapped\n",
    "\n",
    "    state, _ = env.reset() # initialize x_0\n",
    "    disc_state = tuple(discretize_state(state).astype(int)) # only tuples of integers can be used as index \n",
    "    disc_action = pi[disc_state].astype(int)\n",
    "\n",
    "    for k in range(nb_steps):\n",
    "\n",
    "        cont_action = continualize_action(disc_action)\n",
    "        if render:\n",
    "            env.render() # comment out for faster execution\n",
    "        state, reward, terminated, _, _  = env.step(cont_action)\n",
    "        disc_state = tuple(discretize_state(state).astype(int))\n",
    "\n",
    "        if terminated:\n",
    "            break\n",
    "\n",
    "        disc_action = pi[disc_state].astype(int) # exploitative action\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6060d467a9e73671b8c4c038ee9422d",
     "grade": true,
     "grade_id": "cell-17792193ff75f321",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4547c78804a8a7e00b080665860343c3",
     "grade": false,
     "grade_id": "cell-6c921cba34a87b7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train\n",
    "print(\"Run without planning\")\n",
    "no_planning_history, no_planning_pi = pendulumDynaQ(alpha=0.1, gamma=0.9, epsilon=0.1, n=0, nb_episodes=5000, nb_steps=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f973584a51efcb3d28a9321a3074da7f",
     "grade": false,
     "grade_id": "cell-6e95fa1942d32845",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run and render the experiment\n",
    "experiment(no_planning_pi, nb_steps=300, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2176cfb36503b28829a5f5a32ea0934c",
     "grade": true,
     "grade_id": "cell-236faf8290c72bc3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "900633014c729ef21b06d9584036df2a",
     "grade": false,
     "grade_id": "cell-e97227c315bad07d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train\n",
    "print(\"Run with planning\")\n",
    "with_planning_history, with_planning_pi = pendulumDynaQ(alpha=0.1, gamma=0.9, epsilon=0.1, n=9, nb_episodes=500, nb_steps=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "734a92dabacdce8bfc0813f65183ec12",
     "grade": false,
     "grade_id": "cell-2950e36d13673fb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run and render the experiment\n",
    "experiment(with_planning_pi, nb_steps=300, render=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85874bfc353d6f3cfede5be664a485ae",
     "grade": false,
     "grade_id": "cell-f874b3a97814be53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now lets compare the cumulative rewards:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2868984e16b084a304330d9107a46c85",
     "grade": false,
     "grade_id": "cell-4fc08c4ca8bbd031",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(no_planning_history)\n",
    "plt.plot(with_planning_history)\n",
    "plt.xlabel(\"episode\")\n",
    "plt.ylabel(r\"$\\sum R$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "925aaf65989a54d0793943c0699dc758",
     "grade": true,
     "grade_id": "cell-de1462d7fe9bdbed",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52e111b5841fc40854fda10ae9b74815",
     "grade": false,
     "grade_id": "cell-2810aacf498563db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2) Simulation-based planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c03de5f9bbb20565795d4991bf7e9a5a",
     "grade": false,
     "grade_id": "cell-eb709d007371a52d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Although it can be useful for small state spaces, building a system model by storing large amounts of state transitions like in task (1) is rarely feasible in engineering. As engineers, we are capable of a more efficient way of system modeling that we can utilize here: differential equations.\n",
    "\n",
    "Using a state-space model allows to efficiently integrate existing pre-knowledge into the Dyna-Q algorithm we already used. To do so, write a class `pendulum_model` that implements a model of the pendulum. This class should work similar to `gymnasium`: it should at least have a `step` and a `reset` method. In the step method, make use of forward Euler integration to simulate the system dynamics. In the reset method, allow to pass an optional initial state to the model, such that we can easily compare model and environment. If no initial state is passed to the `reset` function, a random initial state should be determined.\n",
    "\n",
    "Integrate this model into a Dyna-Q algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18b6c16830863dafa8ede256ddc51238",
     "grade": false,
     "grade_id": "cell-4f43d13fe3da4001",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Model of the pendulum in differential-equation form for change of the angular frequency $\\omega$ and the angle $\\theta$ depending on the torque $T_\\mathrm{u}$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{\\omega} &= -\\frac{3 g}{2 l} \\text{sin}(\\theta +\\pi) + \\frac{1}{J} T_\\mathrm{u}\n",
    "\\\\\n",
    "\\dot{\\theta} &= \\omega\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "Parameters (gravity constant $g$, mass $m$, length  $l$ and intertia $J$ of the pendulum):\n",
    "\n",
    "\\begin{align*}\n",
    "g&=10 \\, \\frac{\\text{m}}{\\text{s}^2}\n",
    "\\\\\n",
    "m&=1 \\, \\text{kg}\n",
    "\\\\\n",
    "l&=1 \\, \\text{m}\n",
    "\\\\\n",
    "J&=\\frac{1}{3} m l^2\n",
    "\\end{align*}\n",
    "\n",
    "Forward Euler integration:\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{x}(k T_S) \\approx \\frac{x[k+1] - x[k]}{T_S}\n",
    "\\end{align*}\n",
    "\n",
    "with sampling time $T_S = 0.05 \\, \\text{s}$\n",
    "\n",
    "Reward function:\n",
    "\n",
    "\\begin{align*}\n",
    "r_{k+1} = -(\\theta^2[k] + 0.1 \\, \\text{s}^2 \\cdot \\omega^2[k] + 0.001 \\frac{1}{(\\text{N}\\text{m})^2} \\cdot T_\\mathrm{u}^2[k])\n",
    "\\end{align*}\n",
    "\n",
    "Limitations of state and action space:\n",
    "\\begin{align*}\n",
    "\\theta &\\in [-\\pi, \\pi]\n",
    "\\\\\n",
    "\\omega &\\in [-8  \\, \\frac{1}{\\text{s}}, 8  \\, \\frac{1}{\\text{s}}]\n",
    "\\\\\n",
    "T_\\mathrm{u} &\\in [-2 \\, \\text{N}\\text{m}, 2 \\, \\text{N}\\text{m}]\n",
    "\\end{align*}\n",
    "\n",
    "And of course input and output space:\n",
    "\\begin{align*}\n",
    "\\text{action}&=T_\\mathrm{u}\n",
    "\\\\\n",
    "\\text{state}&=\n",
    "\\begin{bmatrix}\n",
    "\\text{cos}(\\theta)\\\\\n",
    "\\text{sin}(\\theta)\\\\\n",
    "\\omega\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d90167657de2f08e174139a651e53e5e",
     "grade": false,
     "grade_id": "cell-5b01fba780d2909f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Solution 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "462b1c8592cbfe9e9aa0d70b30ec04f0",
     "grade": true,
     "grade_id": "cell-5d0c5a3e7a69720d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0dba47650a1dc1472f4b581139a62db",
     "grade": false,
     "grade_id": "cell-11f8cac7e03b7f81",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class pendulum_model:\n",
    "    def __init__(self, dt=0.05, m=1, g=10, l=1):\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def reset(self, state=None):\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return state\n",
    "\n",
    "    def step(self, T_u):\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return state, reward\n",
    "\n",
    "    def angle_normalize(self, theta):\n",
    "        # usage of this helper function is optional\n",
    "        return (((theta+np.pi) % (2*np.pi)) - np.pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0dda4616446eb5cd96290a9bf67fff0",
     "grade": false,
     "grade_id": "cell-21f127639f04da34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell is for debugging of the `pendulum_model` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f26b59cee88b03d7933c299376ed5d77",
     "grade": false,
     "grade_id": "cell-1c1d572fbaded77d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1')\n",
    "# removes a builtin time limit of k_T = 200, we want to determine the time limit ourselves\n",
    "env = env.unwrapped\n",
    "\n",
    "model = pendulum_model()\n",
    "\n",
    "state, _ = env.reset()\n",
    "\n",
    "m_state = model.reset(state)  # model is set to state of env\n",
    "\n",
    "nb_episodes = 10000\n",
    "\n",
    "for _ in range(nb_episodes):\n",
    "\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    state, reward, terminated, _, _ = env.step(action)  # take action on env\n",
    "    m_state, m_reward = model.step(action)  # take the same action on model\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "337c2047499ccb029367d7b9dac0fc12",
     "grade": false,
     "grade_id": "cell-48d9727d1bcf9cba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using $-\\mathrm{sin}(\\theta)$ instead of $\\mathrm{sin}(\\theta +\\pi)$ makes no difference when assuming analytical precision, but due to numeric errors these formulations will still yield different results in numpy, mainly because $\\pi$ is represented with finite (float) precision. In order to yield the same numbers as in `gymnasium`, we will still make use of the (more cumbersome) $\\mathrm{sin}(\\theta +\\pi)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "013b51a6358b2f4ae1fd463ccf2deaba",
     "grade": false,
     "grade_id": "cell-0a63f527a46b3115",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write a function for the Dyna-Q algorithm, which uses the model we defined above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "357875de36a081248f35aef121a91914",
     "grade": false,
     "grade_id": "cell-ab054c945a614362",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pendulumModelDynaQ(alpha, gamma, epsilon, n, nb_episodes, nb_steps):\n",
    "\n",
    "    env = gym.make('Pendulum-v1')  # , render_mode=\"human\"\n",
    "    env = env.unwrapped\n",
    "    model = pendulum_model() #Wrong parameters for later m=5, g=20, l=2\n",
    "\n",
    "    action_values = np.zeros([d_theta, d_theta, d_omega, d_T])\n",
    "    pi = np.zeros([d_theta, d_theta, d_omega])\n",
    "\n",
    "    # we can use this to figure out how well the learning worked\n",
    "    cumulative_reward_history = []\n",
    "\n",
    "    pbar = tqdm(range(nb_episodes), position=0, leave=True)\n",
    "\n",
    "    for j in pbar:\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return cumulative_reward_history, pi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73126d858dc0b06a1c8577372bf84534",
     "grade": false,
     "grade_id": "cell-6f4a8238fb568bf1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following cell to compare the learing from experience from 1) to the learning using the defined model: (Beware, nb_steps = 10000 can take some time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1b49c106514a5c73958aa944b8b7acf",
     "grade": false,
     "grade_id": "cell-55a20ee55df4b168",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train both setups once\n",
    "print(\"Run with planning from experience\")\n",
    "exp_planning_history, exp_planning_pi = pendulumDynaQ(alpha=0.1, gamma=0.9, epsilon=0.1, n=19, nb_episodes=30, nb_steps=10000)\n",
    "\n",
    "print(\"Run with planning from model\")\n",
    "model_planning_history, model_planning_pi = pendulumModelDynaQ(alpha=0.1, gamma=0.9, epsilon=0.1, n=19, nb_episodes=30, nb_steps=10000)\n",
    "\n",
    "\n",
    "plt.plot(exp_planning_history, label=\"exp\")\n",
    "plt.plot(model_planning_history, label=\"model\")\n",
    "plt.xlabel(\"episode\")\n",
    "plt.ylabel(r\"$\\sum R$\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17d6ff5519d7afa9a6cdd9d651d0b2aa",
     "grade": false,
     "grade_id": "cell-1a7bfac51c16c83f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following cell to execute the policy we got using the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54d5159a93d836d08707ad559fcc1f00",
     "grade": false,
     "grade_id": "cell-05c7abf525fbaa40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "experiment(model_planning_pi, nb_steps=300, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb0258449638e4e2199308a086d46b6d",
     "grade": false,
     "grade_id": "cell-54c9b97a5d245359",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Extra-task:\n",
    "Change the model parameters (e.g. $g$, $m$, $l$) so that our model differs from the \"real world\" (we got from gym).\n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6d3be45817812136df229b533f6878",
     "grade": false,
     "grade_id": "cell-ce6069a5b3db12d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "By changing the parameters our model differs from the \"real world\". Depending on the amount of difference, the learing curve looks worse than the one with the correct values. \n",
    "The experiment result is also depending on the random starting position. \n",
    "Depending on the parameter difference, the experiment can not be executed successfully any more. \n",
    "\n",
    "Try to change the parameters on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "281bad375b17facb3f3b5971ffcaec00",
     "grade": true,
     "grade_id": "cell-35f013c58ce9bdca",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b54b45bd488df843db9bf69ece13eaa",
     "grade": true,
     "grade_id": "cell-a6e85462116fce6c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4df9afa58d6c2321046435cefe965655",
     "grade": true,
     "grade_id": "cell-27a52b7e54657710",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f488ee5c554981931723485a6d5d685",
     "grade": true,
     "grade_id": "cell-2bc64d2fdf9455ef",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
