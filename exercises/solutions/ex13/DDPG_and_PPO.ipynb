{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57facccd",
   "metadata": {},
   "source": [
    "# Exercice 13) Deep Deterministic Policy Gradients and Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe402026",
   "metadata": {},
   "source": [
    "In this exercise we will investigate two state-of-the-art algorithms: deep deterministic policy gradient (DDPG) and proximal policy optimization (PPO).\n",
    "\n",
    "We will examine their performance on [Goddard's rocket problem](https://github.com/osannolik/gym-goddard).\n",
    "This environment comes prepackaged in this notebook's folder, so it can be just imported.\n",
    "\n",
    "```\n",
    "First formulated by R. H. Goddard around 1910, this is a classical problem within dynamic optimization and optimal control. The task is simply to find the optimal thrust profile for a vertically ascending rocket in order for it to reach the maximum possible altitude, given that its mass decreases as the fuel is spent and that it is subject to varying drag and gravity.\n",
    "\n",
    "The state, and the gym's observation space, of the rocket is its vertical position, velocity and mass.\n",
    "\n",
    "The rocket engine is assumed to be throttled such that the thrust can be continuously controlled between 0 to some maximum limit.\n",
    "```\n",
    "\n",
    "![](https://github.com/osannolik/gym-goddard/blob/master/animation.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9ccabd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rocket_env import GoddardEnv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3a5c7",
   "metadata": {},
   "source": [
    "## 1) DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1eaafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af50f7af",
   "metadata": {},
   "source": [
    "## 2) PPO\n",
    "\n",
    "The [original paper from 2017](https://arxiv.org/abs/1707.06347) for the PPO came up with an idea to combine A2C (having multiple workers) and TRPO (using a trust region to improve the actor).\n",
    "The PPO algorithm achieves this by hard clipping gradients in order to ensure that new policies won't be too far away from old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "81d06d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, DDPG, A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import torch\n",
    "\n",
    "policy_kwargs = dict(activation_fn=torch.nn.Tanh, net_arch=dict(pi=[8] * 2, qf=[8] * 2))\n",
    "\n",
    "n_envs = 4\n",
    "#env = make_vec_env(GoddardEnv, n_envs=n_envs, seed=0)\n",
    "env = GoddardEnv()\n",
    "model = PPO('MlpPolicy', env, n_steps=1280, n_epochs=100,  verbose=0, device='cpu', learning_rate=1e-3, batch_size=64)\n",
    "model = model.learn(total_timesteps=int(1e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "31113c41",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-6648dedd8841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# env.action_space.sample()#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcum_rew\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/projects/reinforcement_learning_course_materials/exercises/solutions/ex13/rocket_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfo_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tools/anaconda3/envs/torch/lib/python3.7/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tools/anaconda3/envs/torch/lib/python3.7/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# TODO canvas.flip?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sync_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tools/anaconda3/envs/torch/lib/python3.7/site-packages/pyglet/gl/xlib.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vsync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_vsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mglx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglXSwapBuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_display\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglx_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_episodes = 5\n",
    "#model = PPO('MlpPolicy', env, n_steps=1280, n_epochs=100,  verbose=0, device='cpu', learning_rate=1e-3, batch_size=64)\n",
    "max_steps_per_episode = 500\n",
    "tst_logs = {'rewards': []}\n",
    "for ep in range(n_episodes):\n",
    "    obs = env.reset()\n",
    "    done = np.zeros(n_envs, dtype=np.bool)\n",
    "    cum_rew = 0\n",
    "    k = 0\n",
    "    while not np.all(done) and k < max_steps_per_episode:\n",
    "        action, _state = model.predict(obs, deterministic=True) # env.action_space.sample()#\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        cum_rew += reward\n",
    "        k += 1\n",
    "\n",
    "    tst_logs['rewards'].append(cum_rew)\n",
    "rewards = np.array(tst_logs['rewards']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dcb7fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c55dfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01020396, 0.01012596, 0.01002829, 0.01072063, 0.01090478])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7284f751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward ± std.dev: 0.010397 ± 0.00034906948041522716\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.scatter(np.random.randn(rewards.size), rewards, label='Cum. Reward')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Reached height')\n",
    "plt.ylim(0, 0.05)\n",
    "plt.xticks([])\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "print(f'Mean reward ± std.dev: {rewards.mean():.6f} ± {rewards.std()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
