{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c833698b7dad927d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 6: Multi-Step Bootstrapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7cf627dacfec200a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise we will have a look at n-step methods and eligibility trace. The n-step methods are a class of reinforcement learning algorithms that are an abstraction of the Monte Carlo and TD(0) methods discussed earlier and include them as special cases. Furthermore, we also consider the eligibility traces, which take a reverse approach to determining the state values. The environment we will be dealing with is a little more typical for control research: the inverted pendulum. \n",
    "\n",
    "![](https://miro.medium.com/max/1000/1*TNo3x9zDi1lVOH_3ncG7Aw.gif)\n",
    "\n",
    "To implement this environment, we will make use of the gymnasium library. Please install the gymnasium library within your preferred Python environment using:\n",
    "\n",
    "```pip install gymnasium```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68ba542456c544d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9853bfaec1d8013",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check if the installation and import work by executing the following cell. A window with an animation of the pendulum should open, display some random actions, and close automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e133fbe2615fd5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "env = env.unwrapped # removes a built-in time limit of k_T = 200, we want to determine the time limit ourselves\n",
    "\n",
    "state, _ = env.reset()\n",
    "for _ in range(300):\n",
    "    # env.render()\n",
    "    state, reward, terminated, _, _ = env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f29246bdc3e421c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The goal of this environment is to bring the pendulum into the upper neutral position, where the angle $\\theta = 0$ and the angular velocitiy $\\frac{\\text{d}}{\\text{d}t}\\theta=\\omega=0$. The reward function is already designed that way and does not need further specification. For further information about the environment you may refer to the code and documentation of Farama Foundation's `gymnasium`:\n",
    "\n",
    "[Documentation of the gymnasium pendulum](https://gymnasium.farama.org/environments/classic_control/pendulum/)\n",
    "\n",
    "[Pendulum environment in the gymnasium Github repository](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/pendulum.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8570b84cc28ffc4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1) Discretization of Action and State Space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee59383187979c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Unlike the racetrack environment, the inverted pendulum comes with a continuous action and state space. Although it is possible to handle systems with these characteristics, we did not yet learn how to deal with them. For now, we only know how to implement agents for discrete action and state spaces. Accordingly, we will also try to represent the inverted pendulum within a discrete state / action space. For this, a discretization is necessary.\n",
    "\n",
    "The pendulum has three state variables relating to the momentary angular position $\\theta$:\n",
    "\\begin{align*}\n",
    "    x=\\begin{bmatrix}\n",
    "    \\text{cos}(\\theta)\\\\\n",
    "    \\text{sin}(\\theta)\\\\\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\theta\n",
    "    \\end{bmatrix}\n",
    "    \\in\n",
    "    \\begin{bmatrix}\n",
    "    [-1, 1]\\\\\n",
    "    [-1, 1]\\\\\n",
    "    [-8 \\, \\frac{1}{\\text{s}}, 8 \\, \\frac{1}{\\text{s}}]\n",
    "    \\end{bmatrix},\n",
    "\\end{align*}\n",
    "\n",
    "and one input variable which relates to the torque applied at the axis of rotation:\n",
    "\n",
    "$u = T \\in [-2 \\, \\text{N}\\cdot\\text{m}, 2 \\, \\text{N}\\cdot\\text{m}]$\n",
    "\n",
    "After the discretization, we want the system to be defined on sets of non-negative natural numbers:\n",
    "\n",
    "\\begin{align*}\n",
    "    x_d =\n",
    "    \\text{discretize_state}(x)\n",
    "    \\in\n",
    "    \\begin{bmatrix}\n",
    "    \\{0,1,2,...,d_{\\theta}-1\\}\\\\\n",
    "    \\{0,1,2,...,d_{\\theta}-1\\}\\\\\n",
    "    \\{0,1,2,...,d_{\\omega}-1\\}\n",
    "    \\end{bmatrix},\n",
    "\\end{align*}\n",
    "\n",
    "$\n",
    "u_d =\n",
    "\\text{discretize_action}(u)\n",
    "\\in\n",
    "\\{0,1,2,...,d_{T}-1\\}.\n",
    "$\n",
    "\n",
    "Since action is selected within the discrete action space, we need to transform it accordingly:\n",
    "\n",
    "$\n",
    "u=\n",
    "\\text{continualize_action}(u_d):\n",
    "\\{0,1,2,...,d_{T}-1\\} \\rightarrow [-2 \\, \\text{N}\\cdot\\text{m}, 2 \\, \\text{N}\\cdot\\text{m}]\n",
    ".\n",
    "$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28b6b992373b4a65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write the functions `discretize_state` and `continualize_action`, such that a discrete RL agent can be applied. (Please note that all I/O of `gymnasium` consists of numpy arrays.) Write the functions in such a way that the number of discretization intervals $d_\\theta, d_\\omega, d_T$ are parameters that can be changed for different tests. The discretization intervals should be uniformly distributed on their respective state space.\n",
    "\n",
    "A parametrization of $d_\\theta = d_\\omega = d_T = 15$ can be used to yield satisfactory results in this exercise.\n",
    "However, does it make a difference if the number of discretization intervals is odd or even? If yes, what should be preferred for the given environment? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfd4a4f7a22ce35c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Solution 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cf67ba4807c7ce8c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Code given below.\n",
    "\n",
    "The number of discretization intervals can in fact make a difference in this case. The inverted pendulum can be considered as solved when brought into the upper neutral position $\\theta=0, \\omega=0$. The state as given by `gymnasium` would therefore be:\n",
    "\n",
    "\\begin{align*}\n",
    "x_\\text{neutral}=\n",
    "\\begin{bmatrix}\n",
    "\\text{cos}(0)\\\\\n",
    "\\text{sin}(0)\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{bmatrix},\n",
    "u_\\text{neutral}=0\n",
    "\\end{align*}\n",
    "\n",
    "Consequently, the discretization / continualization should allow for precise transformation of this state, which is given when assuming an odd number of discretization intervals. If one uses an even number of intervals, one interval boundary will be located exactly at zero, potentially leading to rapid bouncing around the neutral position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af38d4d166803785",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d_T = 15\n",
    "d_theta = 15\n",
    "d_omega = 15\n",
    "\n",
    "\n",
    "def discretize_state(states):\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "\n",
    "    limits = [1, 1, 8]\n",
    "    nb_disc_intervals = [d_theta, d_theta, d_omega]\n",
    "\n",
    "    q_intervals = [np.linspace(-l, l, i+1)\n",
    "                   for l, i in zip(limits, nb_disc_intervals)]\n",
    "    # Clipping is necessary due to linspacing with an additional interval, which in turn is necessary\n",
    "    #  for how numpy.digitize works (i.e., it floors the continuous value)\n",
    "    return np.array([np.digitize(s, q).clip(max=q.size - 1) - 1 for s, q in zip(states, q_intervals)],\n",
    "                    dtype=int)  # int is necessary for indexing\n",
    "    # END SOLUTION\n",
    "\n",
    "\n",
    "def continualize_action(disc_action):\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "\n",
    "    limit = 2\n",
    "    interval_length = 2 / (d_T-1)\n",
    "    norm_action = disc_action * interval_length\n",
    "    cont_action = (norm_action - 1) * limit\n",
    "    return np.array(cont_action).flatten()\n",
    "\n",
    "    # END SOLUTION\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-54296429c6a25f98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following cell for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-755b0b9277910870",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "state, _ = env.reset()\n",
    "for _ in range(5):\n",
    "    disc_action = np.random.choice(range(9))\n",
    "    cont_action = continualize_action(disc_action)\n",
    "    print(\"discrete action: {}, continuous action: {}\".format(disc_action, cont_action))\n",
    "    \n",
    "    state, reward, terminated, _, _ = env.step(cont_action) # take a random action\n",
    "    disc_state = discretize_state(state)\n",
    "    print(\"discrete state: {}, continuous state: {}\".format(disc_state, state))\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7050729ab9b288bc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## Discretization Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-191ecd76d4787fb5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cos_theta = np.linspace(-1, 1, 10000)\n",
    "sin_theta = np.linspace(-1, 1, 10000)\n",
    "omega = np.linspace(-8, 8, 10000)\n",
    "T = np.arange(0, d_T, 1)\n",
    "\n",
    "disc_states = np.array([discretize_state(np.array([c, s, o])) for c, s, o in zip(cos_theta, sin_theta, omega)])\n",
    "cont_actions = [continualize_action(np.array(t)) for t in T]\n",
    "\n",
    "plt.plot(cos_theta, disc_states[:, 0])\n",
    "plt.xlabel(r\"cos$(\\theta)$, sin$(\\theta)$\")\n",
    "plt.ylabel(r\"cos${}_d$, sin${}_d$\")\n",
    "plt.grid('major')\n",
    "plt.show()\n",
    "plt.plot(omega, disc_states[:, 2])\n",
    "plt.xlabel(r\"$\\omega / \\frac{1}{\\mathrm{s}}$\")\n",
    "plt.ylabel(r\"$\\omega_d$\")\n",
    "plt.grid('major')\n",
    "plt.show()\n",
    "plt.plot(T, cont_actions, 'o-')\n",
    "plt.xlabel(r\"$T_d$\")\n",
    "plt.ylabel(r\"$T / \\mathrm{N} \\cdot \\mathrm{m}$\")\n",
    "plt.grid('major')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2575b2d2065717a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2) n-Step Sarsa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-71c349849a7bdad7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write an on-policy n-step Sarsa control algorithm for the inverted pendulum from scratch. This time, no code template is given. \n",
    "\n",
    "Use the following parameters: $\\alpha=0.1, \\gamma=0.9, \\varepsilon=0.1, n=10$ with 500 time steps in 2000 episodes.\n",
    "\n",
    "![](nStepSARSA_Algo.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-877e2e0ac6a7510e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## Solution 2)\n",
    "\n",
    "Execution might take long due to the \"render\" command, but this allows to observe the learning. Comment out to execute faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-37c9e8a6c5268048",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004991292953491211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d271e3a43854c43856720f8c8a0dff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v1') # , render_mode=\"human\"\n",
    "env = env.unwrapped\n",
    "\n",
    "alpha = 0.1  # learning rate\n",
    "gamma = 0.9  # discount factor\n",
    "epsilon = 0.1  # epsilon greedy parameter\n",
    "n = 10  # steps between updates\n",
    "\n",
    "nb_episodes = 2000  # number of episodes\n",
    "nb_steps = 500  # length of episodes\n",
    "\n",
    "action_values = np.zeros([d_theta, d_theta, d_omega, d_T])\n",
    "# int is necessary for indexing\n",
    "pi = np.zeros([d_theta, d_theta, d_omega], dtype=int)\n",
    "\n",
    "# we can use this to figure out how well the learning worked\n",
    "cumulative_reward_history = []\n",
    "\n",
    "for j in tqdm(range(nb_episodes), position=0, leave=True):\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "\n",
    "    state, _ = env.reset()  # initialize x_0\n",
    "    terminated = False\n",
    "    # terminal time (not actually needed for the pendulum, but we want to keep it general)\n",
    "    k_T = None\n",
    "\n",
    "    # will be multiplied with the last rewards\n",
    "    discount_array = gamma ** np.arange(n)\n",
    "\n",
    "    disc_state = tuple(discretize_state(state))  # use tuple indexing\n",
    "\n",
    "    disc_action = pi[disc_state]\n",
    "\n",
    "    states.append(disc_state)\n",
    "    actions.append(tuple([disc_action]))\n",
    "\n",
    "    for k in range(nb_steps + n - 2):\n",
    "\n",
    "        if not terminated:\n",
    "            cont_action = continualize_action(disc_action)\n",
    "            # env.render() # comment out for faster execution\n",
    "            state, reward, terminated, _, _ = env.step(cont_action)\n",
    "\n",
    "            disc_state = tuple(discretize_state(state))\n",
    "\n",
    "            states.append(disc_state)\n",
    "            rewards.append(reward)\n",
    "\n",
    "        if not terminated:  # was already checked before step but has to be checked again after step\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                disc_action = np.random.choice(d_T)  # explorative action\n",
    "            else:\n",
    "                disc_action = pi[disc_state]  # exploitative action\n",
    "\n",
    "            actions.append(tuple([disc_action]))\n",
    "\n",
    "        elif k_T == None:  # if necessary, set terminal time\n",
    "            k_T = k\n",
    "\n",
    "        tau = k - n + 1\n",
    "\n",
    "        if tau >= 0:  # test if agent waited long enough to learn\n",
    "            if terminated:\n",
    "                # helps eliminate contemplation of rewards after termination\n",
    "                rewards.append(0)\n",
    "            last_rewards = rewards[-n:]\n",
    "            g = (discount_array * last_rewards).sum()\n",
    "            if not terminated:\n",
    "                g += gamma ** n * action_values[states[k+1] + actions[k+1]]\n",
    "\n",
    "            tau_state = states[tau]\n",
    "            action_values[tau_state + actions[tau]] += alpha * \\\n",
    "                (g - action_values[tau_state + actions[tau]])\n",
    "            pi[tau_state] = np.argmax(action_values[tau_state])\n",
    "\n",
    "        if tau + 1 == k_T:\n",
    "            break\n",
    "\n",
    "    cumulative_reward_history.append(np.sum(rewards))\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "# END SOLUTION\n",
    "pi_learned = np.copy(pi)  # save pi in cache under different name for later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fc8a6d2fe73f71bf",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(cumulative_reward_history)\n",
    "plt.xlabel(\"episode\")\n",
    "plt.ylabel(r\"$\\sum R$\")\n",
    "plt.show()\n",
    "\n",
    "print(np.shape(cumulative_reward_history))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ddebe8848a817b91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Greedy Execution\n",
    "\n",
    "Test the learned policy by pure greedy execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6ffa29bb63e9fc42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "env = env.unwrapped\n",
    "\n",
    "nb_steps = 200\n",
    "\n",
    "state, _ = env.reset() # initialize x_0\n",
    "disc_state = tuple(discretize_state(state)) # use tuple indexing\n",
    "disc_action = pi_learned[disc_state]\n",
    "\n",
    "for k in range(nb_steps):\n",
    "        \n",
    "    cont_action = continualize_action(disc_action)\n",
    "    env.render() # comment out for faster execution\n",
    "    state, reward, terminated, _, _ = env.step(cont_action)\n",
    "    disc_state = tuple(discretize_state(state))\n",
    "        \n",
    "    if terminated:\n",
    "        break\n",
    "        \n",
    "    disc_action = pi_learned[disc_state] # exploitative action\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2cb21bf8569c915a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3) Tree Backups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef9ba6fd56f7dc65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Although n-step Sarsa is a very powerful algorithm, it still needs to be trained on-policy. This is not a problem in simulations, but it might be quite dangerous if used on physical systems. Therefore, we also need an off-policy solution. \n",
    "\n",
    "Use the policy learned in task (2) as a behavior policy when implementing n-step Sarsa with tree backups and compare their learning behavior. Be aware that execution may be time consuming.\n",
    "\n",
    "Use the following parameters: $\\alpha=0.1, \\gamma=0.9, \\varepsilon=0.1, n=5$ with 500 time steps in 10 000 episodes (might take some time).\n",
    "\n",
    "What can we say about the training process? What can we say about the resulting learned policy? Did the agent learn a good policy? Why? Why not?\n",
    "\n",
    "![](nStepTreeBackup_Algo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb4adfe7b82e148f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00205230712890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4912d12f7c435281382647b0f92947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v1') # , render_mode=\"human\"\n",
    "env = env.unwrapped\n",
    "\n",
    "alpha = 0.1 # learning rate\n",
    "gamma = 0.9 # discount factor\n",
    "epsilon = 0.1 # 0.1 # epsilon greedy parameter\n",
    "n = 5 # steps between updates\n",
    "\n",
    "nb_episodes = 10000 # number of episodes\n",
    "nb_steps = 500 # length of episodes\n",
    "\n",
    "action_values = -999 * np.ones([d_theta, d_theta, d_omega, d_T])\n",
    "behavior_policy = np.copy(pi_learned) # pi_learned should be the learned policy from (2), make sure it is active\n",
    "pi = np.zeros([d_theta, d_theta, d_omega], dtype=int)\n",
    "\n",
    "cumulative_reward_history = [] # we can use this to figure out how well the learning worked\n",
    "\n",
    "for j in tqdm(range(nb_episodes), position=0, leave=True):\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "   \n",
    "    state, _ = env.reset() # initialize x_0\n",
    "    terminated = False\n",
    "    k_T = None # terminal time (not actually needed for the pendulum, but we want to keep it general)\n",
    "    \n",
    "    disc_state = tuple(discretize_state(state)) # use tuple indexing\n",
    "    disc_action = behavior_policy[disc_state]\n",
    "    \n",
    "    states.append(disc_state)\n",
    "    actions.append(tuple([disc_action]))\n",
    "\n",
    "    for k in range(nb_steps + n - 2):\n",
    "        \n",
    "        if not terminated:\n",
    "            cont_action = continualize_action(disc_action)\n",
    "            # env.render() # comment out for faster execution\n",
    "            state, reward, terminated, _, _ = env.step(cont_action)\n",
    "            \n",
    "            disc_state = tuple(discretize_state(state))\n",
    "\n",
    "            states.append(disc_state)\n",
    "            rewards.append(reward)\n",
    "        \n",
    "        if not terminated: # was already checked before step but has to be checked again after step\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                disc_action = np.random.choice(d_T) # explorative action\n",
    "            else:\n",
    "                disc_action = behavior_policy[disc_state] # exploitative action\n",
    "                \n",
    "            actions.append(tuple([disc_action]))\n",
    "            \n",
    "        elif k_T == None: # if necessary, set terminal time\n",
    "            k_T = k + 1\n",
    "            \n",
    "        tau = k - n + 1 \n",
    "        \n",
    "        if tau >= 0: # test if agent waited long enough to learn\n",
    "            \n",
    "            g = rewards[-1]\n",
    "            if not terminated:\n",
    "                g += gamma * (pi[states[k+1]] * action_values[states[k+1]]).sum() \n",
    "            \n",
    "            if not k_T == None:\n",
    "                i_idx_start = np.min([k, k_T - 1])\n",
    "            else:\n",
    "                i_idx_start = k\n",
    "                               \n",
    "            i_idx_range = np.arange(i_idx_start, tau, -1) # second entry is exclusive, go backwards in time\n",
    "            \n",
    "            for i in i_idx_range:\n",
    "                # expected action_value of actions that were NOT applied + expected return of action that was applied.\n",
    "                # The expected action would need to be calculated here, but since the trained policy pi is greedy\n",
    "                #  wrt action_values, we can simply get the maximum action_value to obtain the expected action.\n",
    "                #  The probability for the other actions, that are not taken by pi, have a 0% chance under pi.\n",
    "                if actions[i] == pi[states[i]]:\n",
    "                    # Here, the expected return of applied action has 100% chance of happening.\n",
    "                    # Behavior policy and learned policy pi overlap.\n",
    "                    sum_pi_qg = g\n",
    "                else:\n",
    "                    # Here, the learned policy would decide differently from the behavior policy\n",
    "                    sum_pi_qg = np.max(action_values[states[i]])\n",
    "                # 1st entry in states belongs to 0th entry in rewards, \n",
    "                # hence states[i] belongs to rewards[i-1]\n",
    "                g = rewards[i-1] + gamma * sum_pi_qg\n",
    "                \n",
    "            action_values[states[tau] + actions[tau]] += alpha * (g - action_values[states[tau] + actions[tau]])\n",
    "            pi[states[tau]] = np.argmax(action_values[states[tau]])\n",
    "            \n",
    "        if tau + 1 == k_T:\n",
    "            break\n",
    "            \n",
    "    cumulative_reward_history.append(np.sum(rewards))\n",
    "            \n",
    "env.close()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0eb6391db0077e71",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(cumulative_reward_history)\n",
    "plt.xlabel(\"episode\")\n",
    "plt.ylabel(r\"$\\sum R$\")\n",
    "plt.show()\n",
    "\n",
    "print(np.shape(cumulative_reward_history))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c1d56f58872a3dba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Greedy Execution\n",
    "\n",
    "Test the learned policy by pure greedy execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-563faef7628f6cf4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "env = env.unwrapped\n",
    "\n",
    "nb_steps = 200\n",
    "\n",
    "state, _ = env.reset() # initialize x_0\n",
    "disc_state = tuple(discretize_state(state)) # use tuple indexing\n",
    "disc_action = pi[disc_state]\n",
    "\n",
    "for k in range(nb_steps):\n",
    "        \n",
    "    cont_action = continualize_action(disc_action)\n",
    "    env.render() # comment out for faster execution\n",
    "    state, reward, terminated, _, _ = env.step(cont_action)\n",
    "    disc_state = tuple(discretize_state(state))\n",
    "        \n",
    "    if terminated:\n",
    "        break\n",
    "        \n",
    "    disc_action = pi[disc_state] # exploitative action\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Recursive updates: TD($\\lambda$) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both, $n$-step and $\\lambda$-return updates, are based on a forward view. That means we have to wait for future states and rewards before an update can be performed.\n",
    "We therefore introduce an eligibility traces, which follows the general idea that previous actions have significantly led to the current situation. Contrary to n-step learning, however, intuition tells us that more recent decisions had a more severe impact on the present situation than decisions that were made a long time ago. Thus, it may be helpful to integrate a forgetting factor $\\lambda$ which decreases the assumed influence of actions over time.\n",
    "\n",
    "Solution 3 is now to be extended by eligibility traces $z_k(x_k)$ within the action-value update. Test it for different values of $\\lambda$. How sensitive is the process to the choice of $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0049896240234375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a7f803afcd4fb88e806a3bacdadee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marmey\\AppData\\Local\\Temp\\ipykernel_9228\\3972774156.py:75: RuntimeWarning: overflow encountered in multiply\n",
      "  g += gamma * (pi[states[k+1]] *\n",
      "C:\\Users\\marmey\\AppData\\Local\\Temp\\ipykernel_9228\\3972774156.py:108: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  g - action_values[states[tau] + actions[tau]]) * eligibility[states[tau]]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v1')  # , render_mode=\"human\"\n",
    "env = env.unwrapped\n",
    "\n",
    "alpha = 0.1  # learning rate\n",
    "gamma = 0.9  # discount factor\n",
    "epsilon = 0.1  # 0.1 # epsilon greedy parameter\n",
    "n = 1  # steps between updates\n",
    "lamb = 0.95  # forgetting factor\n",
    "\n",
    "nb_episodes = 10000  # number of episodes\n",
    "nb_steps = 500  # length of episodes\n",
    "\n",
    "action_values = -999 * np.ones([d_theta, d_theta, d_omega, d_T])\n",
    "eligibility = np.zeros([d_theta, d_theta, d_omega])\n",
    "# pi_learned should be the learned policy from (2), make sure it is active\n",
    "behavior_policy = np.copy(pi_learned)\n",
    "pi = np.zeros([d_theta, d_theta, d_omega], dtype=int)\n",
    "\n",
    "# we can use this to figure out how well the learning worked\n",
    "cumulative_reward_history = []\n",
    "\n",
    "for j in tqdm(range(nb_episodes), position=0, leave=True):\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "\n",
    "    state, _ = env.reset()  # initialize x_0\n",
    "    terminated = False\n",
    "    # terminal time (not actually needed for the pendulum, but we want to keep it general)\n",
    "    k_T = None\n",
    "\n",
    "    disc_state = tuple(discretize_state(state))  # use tuple indexing\n",
    "    disc_action = behavior_policy[disc_state]\n",
    "\n",
    "    states.append(disc_state)\n",
    "    actions.append(tuple([disc_action]))\n",
    "\n",
    "    for k in range(nb_steps + n - 2):\n",
    "\n",
    "        if not terminated:\n",
    "            cont_action = continualize_action(disc_action)\n",
    "            # env.render() # comment out for faster execution\n",
    "            state, reward, terminated, _, _ = env.step(cont_action)\n",
    "\n",
    "            disc_state = tuple(discretize_state(state))\n",
    "\n",
    "            # update eligibilities\n",
    "            eligibility *= lamb * gamma\n",
    "            eligibility[disc_state] += 1.0\n",
    "\n",
    "            states.append(disc_state)\n",
    "            rewards.append(reward)\n",
    "\n",
    "        if not terminated:  # was already checked before step but has to be checked again after step\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                disc_action = np.random.choice(d_T)  # explorative action\n",
    "            else:\n",
    "                # exploitative action\n",
    "                disc_action = behavior_policy[disc_state]\n",
    "\n",
    "            actions.append(tuple([disc_action]))\n",
    "\n",
    "        elif k_T == None:  # if necessary, set terminal time\n",
    "            k_T = k + 1\n",
    "\n",
    "        tau = k - n + 1\n",
    "\n",
    "        if tau >= 0:  # test if agent waited long enough to learn\n",
    "\n",
    "            g = rewards[-1]\n",
    "            if not terminated:\n",
    "                g += gamma * (pi[states[k+1]] *\n",
    "                              action_values[states[k+1]]).sum()\n",
    "\n",
    "            if not k_T == None:\n",
    "                i_idx_start = np.min([k, k_T - 1])\n",
    "            else:\n",
    "                i_idx_start = k\n",
    "\n",
    "            # second entry is exclusive, go backwards in time\n",
    "            i_idx_range = np.arange(i_idx_start, tau, -1)\n",
    "\n",
    "            for i in i_idx_range:\n",
    "                # expected action_value of actions that were NOT applied + expected return of action that was applied.\n",
    "                # The expected action would need to be calculated here, but since the trained policy pi is greedy\n",
    "                #  wrt action_values, we can simply get the maximum action_value to obtain the expected action.\n",
    "                #  The probability for the other actions, that are not taken by pi, have a 0% chance under pi.\n",
    "                if actions[i] == pi[states[i]]:\n",
    "                    # Here, the expected return of applied action has 100% chance of happening.\n",
    "                    # Behavior policy and learned policy pi overlap.\n",
    "                    sum_pi_qg = g\n",
    "                else:\n",
    "                    # Here, the learned policy would decide differently from the behavior policy\n",
    "                    sum_pi_qg = np.max(action_values[states[i]])\n",
    "                # 1st entry in states belongs to 0th entry in rewards,\n",
    "                # hence states[i] belongs to rewards[i-1]\n",
    "                g = rewards[i-1] + gamma * sum_pi_qg\n",
    "\n",
    "            # print(f'{(states[tau] + actions[tau])=}')\n",
    "            # print(f'{states[tau]=}')\n",
    "            # print(f'{eligibility.shape}')\n",
    "            # raise\n",
    "\n",
    "            action_values[states[tau] + actions[tau]] += alpha * (\n",
    "                g - action_values[states[tau] + actions[tau]]) * eligibility[states[tau]]\n",
    "            pi[states[tau]] = np.argmax(action_values[states[tau]])\n",
    "\n",
    "        if tau + 1 == k_T:\n",
    "            break\n",
    "\n",
    "    cumulative_reward_history.append(np.sum(rewards))\n",
    "\n",
    "env.close()\n",
    "\n",
    "# END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(cumulative_reward_history)\n",
    "plt.xlabel(\"episode\")\n",
    "plt.ylabel(r\"$\\sum R$\")\n",
    "plt.show()\n",
    "\n",
    "print(np.shape(cumulative_reward_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "env = env.unwrapped\n",
    "\n",
    "nb_steps = 200\n",
    "\n",
    "state, _ = env.reset() # initialize x_0\n",
    "disc_state = tuple(discretize_state(state)) # use tuple indexing\n",
    "disc_action = pi[disc_state]\n",
    "\n",
    "for k in range(nb_steps):\n",
    "        \n",
    "    cont_action = continualize_action(disc_action)\n",
    "    env.render() # comment out for faster execution\n",
    "    state, reward, terminated, _, _ = env.step(cont_action)\n",
    "    disc_state = tuple(discretize_state(state))\n",
    "        \n",
    "    if terminated:\n",
    "        break\n",
    "        \n",
    "    disc_action = pi[disc_state] # exploitative action\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
